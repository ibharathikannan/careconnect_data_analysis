{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48187fab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "619f95cc",
   "metadata": {},
   "source": [
    "**1. Data Loading & Initial Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec3043ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "--- Dataframe Head ---\n",
      "  visit_id patient_id nurse_id     visit_start_time       visit_end_time  \\\n",
      "0    v1000       p116      n25           1754323849           1754343349   \n",
      "1    v1001       p110      n29           1757349713           1757351093   \n",
      "2    v1002       p109      n23  11/23/2024 09:19 PM  11/23/2024 10:14 PM   \n",
      "3    v1003       p132      n30  07/10/2025 10:18 PM  07/10/2025 11:24 PM   \n",
      "4    v1004       p130      n26           1749741630           1749744990   \n",
      "\n",
      "       service_type visit_location  \\\n",
      "0  General Check-up           Noth   \n",
      "1        Wound Care           East   \n",
      "2  Physical Therapy            Est   \n",
      "3     Physiotherapy           West   \n",
      "4  General Check-up            Est   \n",
      "\n",
      "                                         nurse_notes  \n",
      "0                                                NaN  \n",
      "1  Drive interest respond end ask machine too or ...  \n",
      "2  New only however enough mission wrong sport op...  \n",
      "3                                                NaN  \n",
      "4  Themselves move start push various agency deve...  \n",
      "\n",
      "--- Dataframe Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   visit_id          200 non-null    object\n",
      " 1   patient_id        200 non-null    object\n",
      " 2   nurse_id          200 non-null    object\n",
      " 3   visit_start_time  200 non-null    object\n",
      " 4   visit_end_time    180 non-null    object\n",
      " 5   service_type      200 non-null    object\n",
      " 6   visit_location    200 non-null    object\n",
      " 7   nurse_notes       134 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 12.6+ KB\n",
      "\n",
      "--- Missing Values ---\n",
      "visit_id             0\n",
      "patient_id           0\n",
      "nurse_id             0\n",
      "visit_start_time     0\n",
      "visit_end_time      20\n",
      "service_type         0\n",
      "visit_location       0\n",
      "nurse_notes         66\n",
      "dtype: int64\n",
      "\n",
      "--- Duplicate Visit IDs ---\n",
      "Number of duplicate visit_ids: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/visits.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/raw/visits.csv' not found.\")\n",
    "    print(\"Please generate the dataset first by running 'python scripts/data_generator.py' from the project root.\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    # --- Initial Data Exploration ---\n",
    "    print(\"\\n--- Dataframe Head ---\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\n--- Dataframe Info ---\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\n--- Missing Values ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print(\"\\n--- Duplicate Visit IDs ---\")\n",
    "    print(f\"Number of duplicate visit_ids: {df.duplicated(subset=['visit_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f52723",
   "metadata": {},
   "source": [
    "**2. Data Cleaning & Preprocessing**\n",
    "\n",
    "a. Handle Duplicate visit_id Records\n",
    "\n",
    "The data generator intentionally creates duplicate visit_id entries. We'll remove them, keeping the first occurrence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cefe3ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9 duplicate visit_id records.\n",
      "Remaining records: 191\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Remove duplicate rows based on 'visit_id', keeping the first instance\n",
    "    initial_rows = len(df)\n",
    "    df.drop_duplicates(subset=['visit_id'], keep='first', inplace=True)\n",
    "    print(f\"Removed {initial_rows - len(df)} duplicate visit_id records.\")\n",
    "    print(f\"Remaining records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7769b",
   "metadata": {},
   "source": [
    "b. Standardize Date/Time Formats\n",
    "\n",
    "The visit_start_time and visit_end_time columns have mixed formats. We'll convert them to a standard datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "567abc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data types after timestamp standardization ---\n",
      "visit_start_time    datetime64[ns]\n",
      "visit_end_time      datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "--- Missing timestamps after coercion ---\n",
      "visit_start_time    40\n",
      "visit_end_time      52\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/m8xt2gk918jcn12w3p2xldcm0000gn/T/ipykernel_87958/1492801177.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['visit_start_time'] = pd.to_datetime(df['visit_start_time'], errors='coerce')\n",
      "/var/folders/m2/m8xt2gk918jcn12w3p2xldcm0000gn/T/ipykernel_87958/1492801177.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['visit_end_time'] = pd.to_datetime(df['visit_end_time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Standardize timestamp columns\n",
    "    df['visit_start_time'] = pd.to_datetime(df['visit_start_time'], errors='coerce')\n",
    "    df['visit_end_time'] = pd.to_datetime(df['visit_end_time'], errors='coerce')\n",
    "\n",
    "    print(\"--- Data types after timestamp standardization ---\")\n",
    "    print(df[['visit_start_time', 'visit_end_time']].dtypes)\n",
    "\n",
    "    # Check for any new NaNs created by conversion errors\n",
    "    print(\"\\n--- Missing timestamps after coercion ---\")\n",
    "    print(df[['visit_start_time', 'visit_end_time']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc576a2",
   "metadata": {},
   "source": [
    "**c. Handle Missing Values and Calculate Visit Duration**\n",
    "\n",
    "Now that timestamps are standardized, we can calculate the visit duration. We'll then handle missing visit_end_time values. For this analysis, we will remove records with missing start or end times as duration is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a7b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 52 rows with missing start or end times.\n",
      "\n",
      "--- Missing values after handling ---\n",
      "visit_id                  0\n",
      "patient_id                0\n",
      "nurse_id                  0\n",
      "visit_start_time          0\n",
      "visit_end_time            0\n",
      "service_type              0\n",
      "visit_location            0\n",
      "nurse_notes               0\n",
      "visit_duration_minutes    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/m8xt2gk918jcn12w3p2xldcm0000gn/T/ipykernel_87958/1299720180.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['nurse_notes'].fillna('No Note Provided', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Calculate visit duration in minutes\n",
    "    df['visit_duration_minutes'] = (df['visit_end_time'] - df['visit_start_time']).dt.total_seconds() / 60\n",
    "\n",
    "    # Handle missing timestamps\n",
    "    # For this analysis, we'll remove rows where duration couldn't be calculated\n",
    "    rows_before_drop = len(df)\n",
    "    df.dropna(subset=['visit_start_time', 'visit_end_time'], inplace=True)\n",
    "    print(f\"Removed {rows_before_drop - len(df)} rows with missing start or end times.\")\n",
    "\n",
    "    # For missing nurse_notes, we'll fill them with a placeholder\n",
    "    df['nurse_notes'].fillna('No Note Provided', inplace=True)\n",
    "    print(\"\\n--- Missing values after handling ---\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366d363",
   "metadata": {},
   "source": [
    "d. Address Outliers in Visit Durations\n",
    "\n",
    "The data generator creates unrealistically short and long visits. We'll define reasonable bounds (e.g., 10 to 240 minutes) and remove records outside this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c55676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Visit Duration Statistics (Before Outlier Removal) ---\n",
      "count    139.000000\n",
      "mean      60.244604\n",
      "std       58.619856\n",
      "min        1.000000\n",
      "25%       35.000000\n",
      "50%       53.000000\n",
      "75%       75.000000\n",
      "max      552.000000\n",
      "Name: visit_duration_minutes, dtype: float64\n",
      "\n",
      "Removed 6 records with outlier visit durations.\n",
      "\n",
      "--- Visit Duration Statistics (After Outlier Removal) ---\n",
      "count    133.000000\n",
      "mean      53.586466\n",
      "std       20.411720\n",
      "min       21.000000\n",
      "25%       36.000000\n",
      "50%       53.000000\n",
      "75%       74.000000\n",
      "max       90.000000\n",
      "Name: visit_duration_minutes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Visit Duration Statistics (Before Outlier Removal) ---\")\n",
    "    print(df['visit_duration_minutes'].describe())\n",
    "\n",
    "    # Define reasonable bounds for visit duration\n",
    "    min_duration = 10  # minutes\n",
    "    max_duration = 240 # 4 hours\n",
    "\n",
    "    # Filter out outliers\n",
    "    rows_before_filter = len(df)\n",
    "    df = df[(df['visit_duration_minutes'] >= min_duration) & (df['visit_duration_minutes'] <= max_duration)]\n",
    "    print(f\"\\nRemoved {rows_before_filter - len(df)} records with outlier visit durations.\")\n",
    "\n",
    "    print(\"\\n--- Visit Duration Statistics (After Outlier Removal) ---\")\n",
    "    print(df['visit_duration_minutes'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fbb1c",
   "metadata": {},
   "source": [
    "e. Clean and Standardize Categorical Variables\n",
    "\n",
    "The service_type and visit_location columns contain typos and inconsistencies. We'll standardize them using mapping dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1376b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standardized Categorical Values ---\n",
      "\n",
      "Unique Service Types:\n",
      "['Physical Therapy' 'Wound Care' 'Medication Administration' 'IV Therapy'\n",
      " 'General Check-up']\n",
      "\n",
      "Unique Visit Locations:\n",
      "['East' 'West' 'North' 'South']\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # --- Clean 'service_type' ---\n",
    "    service_type_mapping = {\n",
    "        \"Medication Administrtion\": \"Medication Administration\",\n",
    "        \"WoundCare\": \"Wound Care\",\n",
    "        \"Physiotherapy\": \"Physical Therapy\",\n",
    "        \"General Checkup\": \"General Check-up\"\n",
    "    }\n",
    "    df['service_type'] = df['service_type'].replace(service_type_mapping)\n",
    "    # Also handle 'Unknown' from duplicate processing\n",
    "    df = df[df['service_type'] != 'Unknown']\n",
    "\n",
    "\n",
    "    # --- Clean 'visit_location' ---\n",
    "    location_mapping = {\n",
    "        \"Noth\": \"North\",\n",
    "        \"Suth\": \"South\",\n",
    "        \"Est\": \"East\",\n",
    "        \"Wst\": \"West\"\n",
    "    }\n",
    "    df['visit_location'] = df['visit_location'].replace(location_mapping)\n",
    "\n",
    "    print(\"--- Standardized Categorical Values ---\")\n",
    "    print(\"\\nUnique Service Types:\")\n",
    "    print(df['service_type'].unique())\n",
    "    print(\"\\nUnique Visit Locations:\")\n",
    "    print(df['visit_location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e2ae6",
   "metadata": {},
   "source": [
    "f. Extract Information from nurse_notes\n",
    "\n",
    "We can use regular expressions to extract structured data like temperature and blood pressure, and flag notes containing keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6316668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted data from nurse_notes ---\n",
      "                                          nurse_notes  temperature_f  \\\n",
      "2   New only however enough mission wrong sport op...           99.5   \n",
      "3                                    No Note Provided            NaN   \n",
      "5   Minute suddenly no product much help from data...           97.3   \n",
      "7   Call contain we start age say check success an...            NaN   \n",
      "9   Morning huge campaign than policy authority da...            NaN   \n",
      "10  Still box here everybody save message attentio...          100.0   \n",
      "11                                   No Note Provided            NaN   \n",
      "13  Marriage cause impact reach hit medical box si...            NaN   \n",
      "14                                   No Note Provided            NaN   \n",
      "15  Himself grow green party light everything past...            NaN   \n",
      "\n",
      "   blood_pressure  urgent_flag  \n",
      "2          140/80        False  \n",
      "3             NaN        False  \n",
      "5          128/81        False  \n",
      "7             NaN        False  \n",
      "9             NaN        False  \n",
      "10         128/77        False  \n",
      "11            NaN        False  \n",
      "13            NaN        False  \n",
      "14            NaN        False  \n",
      "15            NaN        False  \n",
      "\n",
      "--- Final Cleaned DataFrame ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 133 entries, 2 to 199\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   visit_id                133 non-null    object        \n",
      " 1   patient_id              133 non-null    object        \n",
      " 2   nurse_id                133 non-null    object        \n",
      " 3   visit_start_time        133 non-null    datetime64[ns]\n",
      " 4   visit_end_time          133 non-null    datetime64[ns]\n",
      " 5   service_type            133 non-null    object        \n",
      " 6   visit_location          133 non-null    object        \n",
      " 7   nurse_notes             133 non-null    object        \n",
      " 8   visit_duration_minutes  133 non-null    float64       \n",
      " 9   temperature_f           23 non-null     float64       \n",
      " 10  blood_pressure          23 non-null     object        \n",
      " 11  urgent_flag             133 non-null    bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(2), object(7)\n",
      "memory usage: 12.6+ KB\n",
      "  visit_id patient_id nurse_id           visit_start_time  \\\n",
      "2    v1002       p109      n23 2024-11-23 21:19:00.000000   \n",
      "3    v1003       p132      n30 2025-07-10 22:18:00.000000   \n",
      "5    v1005       p115      n30 2025-08-27 08:00:48.000000   \n",
      "7    v1007       p147      n24 2025-03-21 19:22:32.645676   \n",
      "9    v1009       p124      n26 2024-12-06 17:34:00.000000   \n",
      "\n",
      "              visit_end_time               service_type visit_location  \\\n",
      "2 2024-11-23 22:14:00.000000           Physical Therapy           East   \n",
      "3 2025-07-10 23:24:00.000000           Physical Therapy           West   \n",
      "5 2025-08-27 08:37:48.000000                 Wound Care           East   \n",
      "7 2025-03-21 20:22:32.645676  Medication Administration          North   \n",
      "9 2024-12-06 18:34:00.000000  Medication Administration           East   \n",
      "\n",
      "                                         nurse_notes  visit_duration_minutes  \\\n",
      "2  New only however enough mission wrong sport op...                    55.0   \n",
      "3                                   No Note Provided                    66.0   \n",
      "5  Minute suddenly no product much help from data...                    37.0   \n",
      "7  Call contain we start age say check success an...                    60.0   \n",
      "9  Morning huge campaign than policy authority da...                    60.0   \n",
      "\n",
      "   temperature_f blood_pressure  urgent_flag  \n",
      "2           99.5         140/80        False  \n",
      "3            NaN            NaN        False  \n",
      "5           97.3         128/81        False  \n",
      "7            NaN            NaN        False  \n",
      "9            NaN            NaN        False  \n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # --- Extract structured data from nurse_notes ---\n",
    "\n",
    "    # Extract Temperature (e.g., \"98.6F\")\n",
    "    df['temperature_f'] = df['nurse_notes'].str.extract(r'PATIENT_TEMP=(\\d{2,3}\\.\\d)F').astype(float)\n",
    "\n",
    "    # Extract Blood Pressure (e.g., \"120/80\")\n",
    "    df['blood_pressure'] = df['nurse_notes'].str.extract(r'BP=(\\d{2,3}/\\d{2,3})')\n",
    "\n",
    "    # --- Flag notes with keywords ---\n",
    "    df['urgent_flag'] = df['nurse_notes'].str.contains(r'\\*\\*\\*CHECK THIS\\*\\*\\*|!!!', case=False, regex=True)\n",
    "\n",
    "    print(\"\\n--- Extracted data from nurse_notes ---\")\n",
    "    print(df[['nurse_notes', 'temperature_f', 'blood_pressure', 'urgent_flag']].head(10))\n",
    "\n",
    "    print(\"\\n--- Final Cleaned DataFrame ---\")\n",
    "    df.info()\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd70de",
   "metadata": {},
   "source": [
    "**3. Save the Cleaned Data**\n",
    "\n",
    "Finally, save the cleaned DataFrame to the data/processed/ directory for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c16f776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to '../data/processed/visits_cleaned.csv' with 133 records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if df is not None:\n",
    "    # Define the output path\n",
    "    output_path = '../data/processed/visits_cleaned.csv'\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save the cleaned dataframe\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nCleaned data saved to '{output_path}' with {len(df)} records.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
